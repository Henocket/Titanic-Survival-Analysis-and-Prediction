{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75617437",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "Decision tree is a popular and simple machine learning algorithm.  The algorithm determines a result based on each feature provided at multiple tree levels.  Every node in a tree signifies a choice.  The node will then either have a leaf node, which is a final choice, or a branch with more nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "3b5347de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "a89bb19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the processed and splitted data\n",
    "\n",
    "xtrain = \"data/X_train.csv\"\n",
    "X_train = pd.read_csv(xtrain)\n",
    "\n",
    "xtest = \"data/X_test.csv\"\n",
    "X_test = pd.read_csv(xtest)\n",
    "\n",
    "ytrain = \"data/y_train.csv\"\n",
    "y_train = pd.read_csv(ytrain)\n",
    "\n",
    "ytest = \"data/y_test.csv\"\n",
    "y_test = pd.read_csv(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "d4e25910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.83      0.81       105\n",
      "           1       0.74      0.68      0.70        74\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.76      0.75      0.75       179\n",
      "weighted avg       0.76      0.77      0.76       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the data into the Decision tree classifier\n",
    "# Get predictions and evaluate the result\n",
    "\n",
    "treeCls = DecisionTreeClassifier()\n",
    "treeCls = treeCls.fit(X_train, y_train)\n",
    "\n",
    "prediction = treeCls.predict(X_test)\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e223c",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "A random forest is another machine learning that uses trees for classification and regression. It is works by combining multiple decision tree which are trained no multiple subset of features instead of all at the same time. The final decision is made by majority vote of the decision trees for classification or by averaging out the trees outcome for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b60da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.87      0.86       105\n",
      "           1       0.81      0.80      0.80        74\n",
      "\n",
      "    accuracy                           0.84       179\n",
      "   macro avg       0.83      0.83      0.83       179\n",
      "weighted avg       0.84      0.84      0.84       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the data into the Random Forest classifier\n",
    "# Get predictions and evaluate the result\n",
    "\n",
    "rdmFrst = RandomForestClassifier()\n",
    "rdmFrst = rdmFrst.fit(X_train, y_train.to_numpy().ravel())\n",
    "prediction = rdmFrst.predict(X_test)\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99499b8",
   "metadata": {},
   "source": [
    "The Random Forest model significantly outperformed the Decision Tree. This improvement can be attributed to Random Forest's use of multiple decision trees trained on different subsets of the data. By aggregating the results from various trees, Random Forest reduces the overfitting problem that is often seen in individual Decision Trees, leading to better generalization on the test data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
