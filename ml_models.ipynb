{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75617437",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "Decision tree is a popular and simple machine learning algorithm.  The algorithm determines a result based on each feature provided at multiple tree levels.  Every node in a tree signifies a choice.  The node will then either have a leaf node, which is a final choice, or a branch with more nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b5347de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a89bb19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the processed and splitted data\n",
    "\n",
    "xtrain = \"data/X_train.csv\"\n",
    "X_train = pd.read_csv(xtrain)\n",
    "\n",
    "xtest = \"data/X_test.csv\"\n",
    "X_test = pd.read_csv(xtest)\n",
    "\n",
    "ytrain = \"data/y_train.csv\"\n",
    "y_train = pd.read_csv(ytrain)\n",
    "\n",
    "ytest = \"data/y_test.csv\"\n",
    "y_test = pd.read_csv(ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4e25910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80       105\n",
      "           1       0.73      0.69      0.71        74\n",
      "\n",
      "    accuracy                           0.77       179\n",
      "   macro avg       0.76      0.75      0.76       179\n",
      "weighted avg       0.76      0.77      0.76       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the data into the Decision tree classifier\n",
    "# Get predictions and evaluate the result\n",
    "\n",
    "treeCls = DecisionTreeClassifier()\n",
    "treeCls = treeCls.fit(X_train, y_train)\n",
    "\n",
    "prediction = treeCls.predict(X_test)\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919e223c",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "A random forest is another machine learning that uses trees for classification and regression. It is works by combining multiple decision tree which are trained no multiple subset of features instead of all at the same time. The final decision is made by majority vote of the decision trees for classification or by averaging out the trees outcome for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60b60da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       105\n",
      "           1       0.83      0.81      0.82        74\n",
      "\n",
      "    accuracy                           0.85       179\n",
      "   macro avg       0.85      0.85      0.85       179\n",
      "weighted avg       0.85      0.85      0.85       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fit the data into the Random Forest classifier\n",
    "# Get predictions and evaluate the result\n",
    "\n",
    "rdmFrst = RandomForestClassifier()\n",
    "rdmFrst = rdmFrst.fit(X_train, y_train.to_numpy().ravel())\n",
    "prediction = rdmFrst.predict(X_test)\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99499b8",
   "metadata": {},
   "source": [
    "The Random Forest model significantly outperformed the Decision Tree. This improvement can be attributed to Random Forest's use of multiple decision trees trained on different subsets of the data. By aggregating the results from various trees, Random Forest reduces the overfitting problem that is often seen in individual Decision Trees, leading to better generalization on the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1247fa5",
   "metadata": {},
   "source": [
    "## Linear Support Vector Classification\n",
    "\n",
    "The linear SVC algorithm classifies data by finding a hyperplane that best separates the data into different classes. The hyperplane depends on critical points that are closest, known as support vectors. Each data instances can be represented as a point in space based on their features. The hyperplane generated by the algorithm will separate the instances, effectively classifying the dataset. The decision boundary, i.e the hyperplane, is directly dependant on the support vectors. The linear SVC is an optimized SVC algorithm for speed and scalabilty."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d647dd7",
   "metadata": {},
   "source": [
    "## Traditional SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4b2415c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.47      0.52       105\n",
      "           1       0.40      0.51      0.45        74\n",
      "\n",
      "    accuracy                           0.49       179\n",
      "   macro avg       0.49      0.49      0.48       179\n",
      "weighted avg       0.51      0.49      0.49       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tradSvc = SVC(class_weight='balanced')\n",
    "tradSvc = tradSvc.fit(X_train, y_train.to_numpy().ravel())\n",
    "prediction = tradSvc.predict(X_test)\n",
    "print(classification_report(y_test, prediction, zero_division=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f7bc79",
   "metadata": {},
   "source": [
    "## Linear SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4eca6401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.86      0.83       105\n",
      "           1       0.78      0.70      0.74        74\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.79      0.78      0.78       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "linSvc = LinearSVC()\n",
    "linSvc = linSvc.fit(X_train, y_train.to_numpy().ravel())\n",
    "prediction = linSvc.predict(X_test)\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab3bed2",
   "metadata": {},
   "source": [
    "The linear SVC model greatly outperforms the traditional SVC algorithm. This is due to poor generalization on the traditional algorithm. The linear algorithm perfroms well on unbalanced data compared to the former."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
